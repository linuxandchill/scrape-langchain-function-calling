{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e240dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key=\"DEFINE_YOUR_KEY_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c2d44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright\n",
    "from langchain.chains import create_extraction_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9e556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_playwright(site):\n",
    "    data = \"\"\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(site)\n",
    "\n",
    "        page_source = await page.content()\n",
    "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "        \n",
    "        for script in soup([\"script\", \"style\"]): # remove all javascript and stylesheet code\n",
    "            script.extract()\n",
    "        # get text\n",
    "        text = soup.get_text()\n",
    "        # break into lines and remove leading and trailing space on each\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        # break multi-headlines into a line each\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "        # drop blank lines\n",
    "        data = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "        await browser.close()\n",
    "    return data\n",
    "\n",
    "output = await run_playwright(\"https://www.youtube.com/@tylerwhatsgood/videos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7e39a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import create_extraction_chain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\", openai_api_key=openai_key)\n",
    "structured_schema = {\n",
    "    \"properties\": {\n",
    "        \"video_name\": {\"type\": \"string\"},\n",
    "        \"views\": {\"type\": \"integer\"},\n",
    "    },\n",
    "    \"required\": [\"video_name\", \"views\"],\n",
    "}\n",
    "extraction_chain = create_extraction_chain(structured_schema, llm)\n",
    "extraction_chain.run(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9846eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_playwright(site):\n",
    "    data = \"\"\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(site)\n",
    "\n",
    "        page_source = await page.content()\n",
    "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "        for script in soup([\"script\", \"style\"]): # remove all javascript and stylesheet code\n",
    "            script.extract()\n",
    "        # get text\n",
    "        text = soup.get_text()\n",
    "        # break into lines and remove leading and trailing space on each\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        # break multi-headlines into a line each\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "        # drop blank lines\n",
    "        data = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "        await browser.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c16b1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = await run_playwright(\"https://www.futuretools.io/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6b2999",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6260e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import create_extraction_chain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\", openai_api_key=openai_key)\n",
    "\n",
    "structured_schema = {\n",
    "    \"properties\": {\n",
    "        \"product\": {\"type\": \"string\"},\n",
    "        \"description\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"product\", \"description\"],\n",
    "}\n",
    "extraction_chain = create_extraction_chain(structured_schema, llm)\n",
    "extraction_chain.run(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b9cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_playwright(site):\n",
    "    data = \"\"\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(site)\n",
    "\n",
    "        page_source = await page.content()\n",
    "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "        for script in soup([\"script\", \"style\"]): # remove all javascript and stylesheet code\n",
    "            script.extract()\n",
    "        # get text\n",
    "        text = soup.get_text()\n",
    "        # break into lines and remove leading and trailing space on each\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        # break multi-headlines into a line each\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "        # drop blank lines\n",
    "        data = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "        await browser.close()\n",
    "    return data\n",
    "\n",
    "output = await run_playwright(\"https://news.ycombinator.com/news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c8340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import create_extraction_chain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\", openai_api_key=openai_key)\n",
    "structured_schema = {\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\"},\n",
    "        \"points\": {\"type\": \"integer\"},\n",
    "        \"comments\": {\"type\": \"integer\"},\n",
    "        \"url\": {\"type\":\"string\"}\n",
    "    },\n",
    "    \"required\": [\"name\", \"points\", \"comments\"],\n",
    "}\n",
    "extraction_chain = create_extraction_chain(structured_schema, llm)\n",
    "extraction_chain.run(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454531ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_playwright(site):\n",
    "    data = \"\"\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(site)\n",
    "\n",
    "        page_source = await page.content()\n",
    "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "        \n",
    "        for script in soup([\"script\", \"style\"]): # remove all javascript and stylesheet code\n",
    "            script.extract()\n",
    "        # get text\n",
    "        text = soup.get_text()\n",
    "        # break into lines and remove leading and trailing space on each\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        # break multi-headlines into a line each\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "        # drop blank lines\n",
    "        data = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "        await browser.close()\n",
    "    return data\n",
    "\n",
    "output = await run_playwright(\"https://www.monster.com/jobs/l-los-angeles-ca?page=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0def6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487a5464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import create_extraction_chain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\", openai_api_key=openai_key)\n",
    "structured_schema = {\n",
    "    \"properties\": {\n",
    "        \"job_name\": {\"type\": \"string\"},\n",
    "        \"posted_date\": {\"type\": \"string\"}\n",
    "    },\n",
    "    \"required\": [\"job_name\", \"posted_date\"],\n",
    "}\n",
    "extraction_chain = create_extraction_chain(structured_schema, llm)\n",
    "extraction_chain.run(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b11e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def run_playwright(site):\n",
    "    data = \"\"\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(site)\n",
    "\n",
    "        page_source = await page.content()\n",
    "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "        \n",
    "        for script in soup([\"script\", \"style\"]): # remove all javascript and stylesheet code\n",
    "            script.extract()\n",
    "        # get text\n",
    "        text = soup.get_text()\n",
    "        # break into lines and remove leading and trailing space on each\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        # break multi-headlines into a line each\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "        # drop blank lines\n",
    "        data = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "        await browser.close()\n",
    "    return data\n",
    "\n",
    "output = await run_playwright(\"https://financialservices.house.gov/about/members.htm\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04319b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import create_extraction_chain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\", openai_api_key=openai_key)\n",
    "structured_schema = {\n",
    "    \"properties\": {\n",
    "        \"member_name\": {\"type\": \"string\"},\n",
    "        \"state\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"member_name\", \"state\"],\n",
    "}\n",
    "extraction_chain = create_extraction_chain(structured_schema, llm)\n",
    "extraction_chain.run(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5c2bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'member_name': 'Patrick McHenry', 'state': 'North Carolina'},\n",
    " {'member_name': 'Frank D. Lucas', 'state': 'Oklahoma'},\n",
    " {'member_name': 'Pete Sessions', 'state': 'Texas'},\n",
    " {'member_name': 'Bill Posey', 'state': 'Florida'},\n",
    " {'member_name': 'Blaine Luetkemeyer', 'state': 'Missouri'},\n",
    " {'member_name': 'Bill Huizenga', 'state': 'Michigan'},\n",
    " {'member_name': 'Ann Wagner', 'state': 'Missouri'},\n",
    " {'member_name': 'Andy Barr', 'state': 'Kentucky'},\n",
    " {'member_name': 'Roger Williams', 'state': 'Texas'},\n",
    " {'member_name': 'French Hill', 'state': 'Arkansas'},\n",
    " {'member_name': 'Tom Emmer', 'state': 'Minnesota'},\n",
    " {'member_name': 'Barry Loudermilk', 'state': 'Georgia'},\n",
    " {'member_name': 'Alexander X. Mooney', 'state': 'West Virginia'},\n",
    " {'member_name': 'Warren Davidson', 'state': 'Ohio'},\n",
    " {'member_name': 'John Rose', 'state': 'Tennessee'},\n",
    " {'member_name': 'Bryan Steil', 'state': 'Wisconsin'},\n",
    " {'member_name': 'William Timmons', 'state': 'South Carolina'},\n",
    " {'member_name': 'Ralph Norman', 'state': 'South Carolina'},\n",
    " {'member_name': 'Dan Meuser', 'state': 'Pennsylvania'},\n",
    " {'member_name': 'Scott Fitzgerald', 'state': 'Wisconsin'},\n",
    " {'member_name': 'Andrew Garbarino', 'state': 'New York'},\n",
    " {'member_name': 'Young Kim', 'state': 'California'},\n",
    " {'member_name': 'Byron Donalds', 'state': 'Florida'},\n",
    " {'member_name': 'Mike Flood', 'state': 'Nebraska'},\n",
    " {'member_name': 'Mike Lawler', 'state': 'New York'},\n",
    " {'member_name': 'Zach Nunn', 'state': 'Iowa'},\n",
    " {'member_name': 'Monica De La Cruz', 'state': 'Texas'},\n",
    " {'member_name': 'Erin Houchin', 'state': 'Indiana'},\n",
    " {'member_name': 'Andy Ogles', 'state': 'Tennessee'},\n",
    " {'member_name': 'Maxine Waters', 'state': 'California'},\n",
    " {'member_name': 'Nydia M. Velázquez', 'state': 'New York'},\n",
    " {'member_name': 'Brad Sherman', 'state': 'California'},\n",
    " {'member_name': 'Gregory W. Meeks', 'state': 'New York'},\n",
    " {'member_name': 'David Scott', 'state': 'Georgia'},\n",
    " {'member_name': 'Stephen F. Lynch', 'state': 'Massachusetts'},\n",
    " {'member_name': 'Al Green', 'state': 'Texas'},\n",
    " {'member_name': 'Emanuel Cleaver, II', 'state': 'Missouri'},\n",
    " {'member_name': 'Jim A. Himes', 'state': 'Connecticut'},\n",
    " {'member_name': 'Bill Foster', 'state': 'Illinois'},\n",
    " {'member_name': 'Joyce Beatty', 'state': 'Ohio'},\n",
    " {'member_name': 'Juan Vargas', 'state': 'California'},\n",
    " {'member_name': 'Josh Gottheimer', 'state': 'New Jersey'},\n",
    " {'member_name': 'Vicente Gonzalez', 'state': 'Texas'},\n",
    " {'member_name': 'Sean Casten', 'state': 'Illinois'},\n",
    " {'member_name': 'Ayanna Pressley', 'state': 'Massachusetts'},\n",
    " {'member_name': 'Steven Horsford', 'state': 'Nevada'},\n",
    " {'member_name': 'Rashida Tlaib', 'state': 'Michigan'},\n",
    " {'member_name': 'Ritchie Torres', 'state': 'New York'},\n",
    " {'member_name': 'Sylvia Garcia', 'state': 'Texas'},\n",
    " {'member_name': 'Nikema Williams', 'state': 'Georgia'},\n",
    " {'member_name': 'Wiley Nickel', 'state': 'North Carolina'},\n",
    " {'member_name': 'Brittany Pettersen', 'state': 'Colorado'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1012e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def find_most_potentially_corrupt_states(data):\n",
    "    state_counts = Counter(item['state'] for item in data)\n",
    "    most_common_state, count = state_counts.most_common(1)[0]\n",
    "    print(\"Most common state:\", most_common_state)\n",
    "    print(\"Congress ppl with potential to become corrupted\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b330b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_most_potentially_corrupt_states(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4a5a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f176fd12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0044ef38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70630e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610a2e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d22b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e1102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b7a081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c97513",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df0772d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1111a2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "askmoney",
   "language": "python",
   "name": "askmoney"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
